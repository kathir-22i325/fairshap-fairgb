{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline- correlation remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                   0\n",
      "Sex                   0\n",
      "Job                   0\n",
      "Housing               0\n",
      "Saving accounts     183\n",
      "Checking account    394\n",
      "Credit amount         0\n",
      "Duration              0\n",
      "Purpose               0\n",
      "Risk                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from src.data.unified_dataloader import load_dataset\n",
    "\n",
    "a, processed_german_credit = load_dataset('german_credit')\n",
    "_, processed_compas = load_dataset('compas')\n",
    "_, processed_adult = load_dataset('adult')\n",
    "_, processed_census_income_kdd = load_dataset('census_income_kdd')\n",
    "_, processed_default_credit = load_dataset('default_credit')\n",
    "_, processed_compas4race = load_dataset('compas4race')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. German credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>sex</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Job_0</th>\n",
       "      <th>Job_1</th>\n",
       "      <th>Job_2</th>\n",
       "      <th>Job_3</th>\n",
       "      <th>Housing_free</th>\n",
       "      <th>Housing_own</th>\n",
       "      <th>...</th>\n",
       "      <th>Checking account_rich</th>\n",
       "      <th>Purpose_business</th>\n",
       "      <th>Purpose_car</th>\n",
       "      <th>Purpose_domestic appliances</th>\n",
       "      <th>Purpose_education</th>\n",
       "      <th>Purpose_furniture/equipment</th>\n",
       "      <th>Purpose_radio/TV</th>\n",
       "      <th>Purpose_repairs</th>\n",
       "      <th>Purpose_vacation/others</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.766456</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.745131</td>\n",
       "      <td>-1.236478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.191404</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949817</td>\n",
       "      <td>2.248194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.183312</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.416562</td>\n",
       "      <td>-0.738668</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  sex  Credit amount  Duration  Job_0  Job_1  Job_2  Job_3  \\\n",
       "0  2.766456    0      -0.745131 -1.236478      0      0      1      0   \n",
       "1 -1.191404    1       0.949817  2.248194      0      0      1      0   \n",
       "2  1.183312    0      -0.416562 -0.738668      0      1      0      0   \n",
       "\n",
       "   Housing_free  Housing_own  ...  Checking account_rich  Purpose_business  \\\n",
       "0             0            1  ...                      0                 0   \n",
       "1             0            1  ...                      0                 0   \n",
       "2             0            1  ...                      0                 0   \n",
       "\n",
       "   Purpose_car  Purpose_domestic appliances  Purpose_education  \\\n",
       "0            0                            0                  0   \n",
       "1            0                            0                  0   \n",
       "2            0                            0                  1   \n",
       "\n",
       "   Purpose_furniture/equipment  Purpose_radio/TV  Purpose_repairs  \\\n",
       "0                            0                 1                0   \n",
       "1                            0                 1                0   \n",
       "2                            0                 0                0   \n",
       "\n",
       "   Purpose_vacation/others  Risk  \n",
       "0                        0     0  \n",
       "1                        0     1  \n",
       "2                        0     0  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_german_credit.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = processed_german_credit.copy()\n",
    "X = df.drop('Risk', axis=1)\n",
    "y = df['Risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_remover(original_X, sensitive_feature=['sex']):\n",
    "    cr = CorrelationRemover(sensitive_feature_ids=sensitive_feature, alpha=0.5)\n",
    "    cr.fit(original_X)\n",
    "    # CorrelationRemover(sensitive_feature_ids=sensitive_feature)\n",
    "    X_transform = cr.transform(original_X)\n",
    "    return X_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.attribution.oracle_metric import perturb_numpy_ver\n",
    "from fairness_measures import marginalised_np_mat, grp1_DP, grp2_EO, grp3_PQP\n",
    "\n",
    "def fairness_value_function(sen_att, priv_val, unpriv_dict, X, model):\n",
    "    X_disturbed = perturb_numpy_ver(\n",
    "        X=X,\n",
    "        sen_att=sen_att,\n",
    "        priv_val=priv_val,\n",
    "        unpriv_dict=unpriv_dict,\n",
    "        ratio=1.0,\n",
    "    )\n",
    "    fx = model.predict_proba(X)[:, 1]\n",
    "    fx_q = model.predict_proba(X_disturbed)[:, 1]\n",
    "    return np.mean(np.abs(fx - fx_q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.attribution import FairnessExplainer\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)  # 5-fold 交叉验证\n",
    "i = 1\n",
    "\n",
    "accuracies_of_origin = []\n",
    "accuracies_of_transform = []\n",
    "DRs_of_origin = []\n",
    "DRs_of_transform = []\n",
    "EOs_of_origin = []\n",
    "EOs_of_transform = []\n",
    "DPs_of_origin = []\n",
    "DPs_of_transform = []\n",
    "PQPs_of_origin = []\n",
    "PQPs_of_transform = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # print(\"-------------------------------------\")\n",
    "    # print(f\"-------------{i}th fold----------------\")\n",
    "    # print(\"-------------------------------------\")\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    # 训练模型\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    sen_att_name = ['sex']\n",
    "    sen_att = [X_val_fold.columns.get_loc(name) for name in sen_att_name]\n",
    "    priv_val = [1]\n",
    "    unpriv_dict = [list(set(X_val_fold.values[:, sa])) for sa in sen_att]\n",
    "    for sa_list, pv in zip(unpriv_dict, priv_val):\n",
    "        sa_list.remove(pv)\n",
    "    fairness_explainer_original = FairnessExplainer(\n",
    "            model=model, \n",
    "            sen_att=sen_att, \n",
    "            priv_val=priv_val, \n",
    "            unpriv_dict=unpriv_dict,\n",
    "            fairshap_base='DR'\n",
    "            )\n",
    "    # 预测\n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    original_accuracy = accuracy_score(y_val_fold , y_val_pred)\n",
    "    original_DR = fairness_value_function(sen_att, priv_val, unpriv_dict, X_val_fold.values, model)\n",
    "\n",
    "    priv_idx = X_val_fold['sex'].to_numpy().astype(bool)\n",
    "    g1_Cm, g0_Cm = marginalised_np_mat(y=y_val_fold, y_hat=y_val_pred, pos_label=1, priv_idx=priv_idx)\n",
    "    original_DP = grp1_DP(g1_Cm, g0_Cm)[0]\n",
    "    original_EO = grp2_EO(g1_Cm, g0_Cm)[0]\n",
    "    original_PQP = grp3_PQP(g1_Cm, g0_Cm)[0]\n",
    "\n",
    "    accuracies_of_origin.append(original_accuracy)\n",
    "    DRs_of_origin.append(original_DR)\n",
    "    DPs_of_origin.append(original_DP)\n",
    "    EOs_of_origin.append(original_EO)\n",
    "    PQPs_of_origin.append(original_PQP)\n",
    "    \n",
    "    ## transform\n",
    "    sensitive_column = X_train_fold['sex'].copy()\n",
    "    model_transform = XGBClassifier()\n",
    "    X_train_transform_without_sen_att = correlation_remover(X_train_fold, sen_att_name)\n",
    "    X_transform_with_sensitive = np.insert(X_train_transform_without_sen_att, 1, sensitive_column, axis=1)\n",
    "    model_transform.fit(X_transform_with_sensitive, y_train_fold)\n",
    "    y_val_transform_pred = model_transform.predict(X_val_fold)\n",
    "    transform_accuracy = accuracy_score(y_val_fold , y_val_transform_pred)\n",
    "    transform_DR = fairness_value_function(sen_att, priv_val, unpriv_dict, X_val_fold.values, model_transform)\n",
    "    g1_Cm_transform, g0_Cm_transform = marginalised_np_mat(y=y_val_fold, y_hat=y_val_transform_pred, pos_label=1, priv_idx=priv_idx)\n",
    "    transform_DP = grp1_DP(g1_Cm_transform, g0_Cm_transform)[0]\n",
    "    transform_EO = grp2_EO(g1_Cm_transform, g0_Cm_transform)[0]\n",
    "    transform_PQP = grp3_PQP(g1_Cm_transform, g0_Cm_transform)[0]\n",
    "\n",
    "    accuracies_of_transform.append(transform_accuracy)\n",
    "    DRs_of_transform.append(transform_DR)\n",
    "    DPs_of_transform.append(transform_DP)\n",
    "    EOs_of_transform.append(transform_EO)\n",
    "    PQPs_of_transform.append(transform_PQP)\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_accuracy:  0.6649999999999999\n",
      "original_DR:  0.07850321\n",
      "original_DP:  0.051212428151272006\n",
      "original_EO:  0.12865149256676855\n",
      "original_PQP:  0.13410967540351496\n",
      "transform_accuracy:  0.6819999999999999\n",
      "transform_DR:  0.0017339538\n",
      "transform_DP:  0.05330876595452962\n",
      "transform_EO:  0.149534537634666\n",
      "transform_PQP:  0.1784764243265364\n"
     ]
    }
   ],
   "source": [
    "print(\"original_accuracy: \", np.mean(accuracies_of_origin))\n",
    "print(\"original_DR: \", np.mean(DRs_of_origin))\n",
    "print(\"original_DP: \", np.mean(DPs_of_origin))\n",
    "print(\"original_EO: \", np.mean(EOs_of_origin))\n",
    "print(\"original_PQP: \", np.mean(PQPs_of_origin))\n",
    "\n",
    "print(\"transform_accuracy: \", np.mean(accuracies_of_transform))\n",
    "print(\"transform_DR: \", np.mean(DRs_of_transform))\n",
    "print(\"transform_DP: \", np.mean(DPs_of_transform))\n",
    "print(\"transform_EO: \", np.mean(EOs_of_transform))\n",
    "print(\"transform_PQP: \", np.mean(PQPs_of_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>race_African-American</th>\n",
       "      <th>race_Asian</th>\n",
       "      <th>race_Caucasian</th>\n",
       "      <th>race_Hispanic</th>\n",
       "      <th>race_Native American</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>c_charge_degree_F</th>\n",
       "      <th>c_charge_degree_M</th>\n",
       "      <th>type_of_assessment_Risk of Recidivism</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.875313</td>\n",
       "      <td>-0.141855</td>\n",
       "      <td>-0.187414</td>\n",
       "      <td>-0.218065</td>\n",
       "      <td>-0.711240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.068808</td>\n",
       "      <td>-0.141855</td>\n",
       "      <td>-0.187414</td>\n",
       "      <td>-0.218065</td>\n",
       "      <td>-0.711240</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.909985</td>\n",
       "      <td>-0.141855</td>\n",
       "      <td>-0.187414</td>\n",
       "      <td>1.775750</td>\n",
       "      <td>0.108063</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex       age  juv_fel_count  juv_misd_count  juv_other_count  \\\n",
       "0    1  2.875313      -0.141855       -0.187414        -0.218065   \n",
       "1    1 -0.068808      -0.141855       -0.187414        -0.218065   \n",
       "2    1 -0.909985      -0.141855       -0.187414         1.775750   \n",
       "\n",
       "   priors_count  race_African-American  race_Asian  race_Caucasian  \\\n",
       "0     -0.711240                      0           0               0   \n",
       "1     -0.711240                      1           0               0   \n",
       "2      0.108063                      1           0               0   \n",
       "\n",
       "   race_Hispanic  race_Native American  race_Other  c_charge_degree_F  \\\n",
       "0              0                     0           1                  1   \n",
       "1              0                     0           0                  1   \n",
       "2              0                     0           0                  1   \n",
       "\n",
       "   c_charge_degree_M  type_of_assessment_Risk of Recidivism  score_text_High  \\\n",
       "0                  0                                      1                0   \n",
       "1                  0                                      1                0   \n",
       "2                  0                                      1                0   \n",
       "\n",
       "   score_text_Low  score_text_Medium  \n",
       "0               1                  0  \n",
       "1               1                  0  \n",
       "2               1                  0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''COMPAS'''\n",
    "df = processed_compas.copy()\n",
    "X = df.drop('two_year_recid', axis=1)\n",
    "y = df['two_year_recid']\n",
    "\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.attribution import FairnessExplainer\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)  # 5-fold 交叉验证\n",
    "i = 1\n",
    "\n",
    "accuracies_of_origin = []\n",
    "accuracies_of_transform = []\n",
    "DRs_of_origin = []\n",
    "DRs_of_transform = []\n",
    "EOs_of_origin = []\n",
    "EOs_of_transform = []\n",
    "DPs_of_origin = []\n",
    "DPs_of_transform = []\n",
    "PQPs_of_origin = []\n",
    "PQPs_of_transform = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # print(\"-------------------------------------\")\n",
    "    # print(f\"-------------{i}th fold----------------\")\n",
    "    # print(\"-------------------------------------\")\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    # 训练模型\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    sen_att_name = ['sex']\n",
    "    sen_att = [X_val_fold.columns.get_loc(name) for name in sen_att_name]\n",
    "    priv_val = [1]\n",
    "    unpriv_dict = [list(set(X_val_fold.values[:, sa])) for sa in sen_att]\n",
    "    for sa_list, pv in zip(unpriv_dict, priv_val):\n",
    "        sa_list.remove(pv)\n",
    "    fairness_explainer_original = FairnessExplainer(\n",
    "            model=model, \n",
    "            sen_att=sen_att, \n",
    "            priv_val=priv_val, \n",
    "            unpriv_dict=unpriv_dict,\n",
    "            fairshap_base='DR'\n",
    "            )\n",
    "    # 预测\n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    original_accuracy = accuracy_score(y_val_fold , y_val_pred)\n",
    "    original_DR = fairness_value_function(sen_att, priv_val, unpriv_dict, X_val_fold.values, model)\n",
    "\n",
    "    priv_idx = X_val_fold['sex'].to_numpy().astype(bool)\n",
    "    g1_Cm, g0_Cm = marginalised_np_mat(y=y_val_fold, y_hat=y_val_pred, pos_label=1, priv_idx=priv_idx)\n",
    "    original_DP = grp1_DP(g1_Cm, g0_Cm)[0]\n",
    "    original_EO = grp2_EO(g1_Cm, g0_Cm)[0]\n",
    "    original_PQP = grp3_PQP(g1_Cm, g0_Cm)[0]\n",
    "\n",
    "    accuracies_of_origin.append(original_accuracy)\n",
    "    DRs_of_origin.append(original_DR)\n",
    "    DPs_of_origin.append(original_DP)\n",
    "    EOs_of_origin.append(original_EO)\n",
    "    PQPs_of_origin.append(original_PQP)\n",
    "    \n",
    "    ## transform\n",
    "    sensitive_column = X_train_fold['sex'].copy()\n",
    "    model_transform = XGBClassifier()\n",
    "    X_train_transform_without_sen_att = correlation_remover(X_train_fold, sen_att_name)\n",
    "    X_transform_with_sensitive = np.insert(X_train_transform_without_sen_att, 0, sensitive_column, axis=1)\n",
    "    model_transform.fit(X_transform_with_sensitive, y_train_fold)\n",
    "    y_val_transform_pred = model_transform.predict(X_val_fold)\n",
    "    transform_accuracy = accuracy_score(y_val_fold , y_val_transform_pred)\n",
    "    transform_DR = fairness_value_function(sen_att, priv_val, unpriv_dict, X_val_fold.values, model_transform)\n",
    "    g1_Cm_transform, g0_Cm_transform = marginalised_np_mat(y=y_val_fold, y_hat=y_val_transform_pred, pos_label=1, priv_idx=priv_idx)\n",
    "    transform_DP = grp1_DP(g1_Cm_transform, g0_Cm_transform)[0]\n",
    "    transform_EO = grp2_EO(g1_Cm_transform, g0_Cm_transform)[0]\n",
    "    transform_PQP = grp3_PQP(g1_Cm_transform, g0_Cm_transform)[0]\n",
    "\n",
    "    accuracies_of_transform.append(transform_accuracy)\n",
    "    DRs_of_transform.append(transform_DR)\n",
    "    DPs_of_transform.append(transform_DP)\n",
    "    EOs_of_transform.append(transform_EO)\n",
    "    PQPs_of_transform.append(transform_PQP)\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_accuracy:  0.6698091989354125\n",
      "original_DR:  0.08830647\n",
      "original_DP:  0.1548324663847108\n",
      "original_EO:  0.12428469251342018\n",
      "original_PQP:  0.04916781015470504\n",
      "transform_accuracy:  0.6698070843701911\n",
      "transform_DR:  0.005672279\n",
      "transform_DP:  0.11084330858040499\n",
      "transform_EO:  0.06713923474962401\n",
      "transform_PQP:  0.07494560579537339\n"
     ]
    }
   ],
   "source": [
    "print(\"original_accuracy: \", np.mean(accuracies_of_origin))\n",
    "print(\"original_DR: \", np.mean(DRs_of_origin))\n",
    "print(\"original_DP: \", np.mean(DPs_of_origin))\n",
    "print(\"original_EO: \", np.mean(EOs_of_origin))\n",
    "print(\"original_PQP: \", np.mean(PQPs_of_origin))\n",
    "\n",
    "print(\"transform_accuracy: \", np.mean(accuracies_of_transform))\n",
    "print(\"transform_DR: \", np.mean(DRs_of_transform))\n",
    "print(\"transform_DP: \", np.mean(DPs_of_transform))\n",
    "print(\"transform_EO: \", np.mean(EOs_of_transform))\n",
    "print(\"transform_PQP: \", np.mean(PQPs_of_transform))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlabel_fair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
