{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments of Benchmark methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### baseline - experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "c:\\Users\\ZhuLi\\anaconda3\\envs\\unlabel_fair\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Github-desktop\\Unlabeled-Fairness\\src\\benchmark_methods\\benchmark_methods.py:443: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(mmd_score)  # Return the square root for interpretability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "---!! on german_credit dataset !!---\n",
      "-------------------------------------\n",
      "Age                   0\n",
      "Sex                   0\n",
      "Job                   0\n",
      "Housing               0\n",
      "Saving accounts     183\n",
      "Checking account    394\n",
      "Credit amount         0\n",
      "Duration              0\n",
      "Purpose               0\n",
      "Risk                  0\n",
      "dtype: int64\n",
      "-------------------------------------\n",
      "-------------0th fold----------------\n",
      "-------------------------------------\n",
      "diff_count: 20000\n",
      "-------------------------------------\n",
      "-------------1th fold----------------\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github-desktop\\Unlabeled-Fairness\\src\\benchmark_methods\\benchmark_methods.py:443: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(mmd_score)  # Return the square root for interpretability\n",
      "d:\\Github-desktop\\Unlabeled-Fairness\\src\\benchmark_methods\\benchmark_methods.py:443: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(mmd_score)  # Return the square root for interpretability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_count: 20000\n",
      "-------------------------------------\n",
      "-------------2th fold----------------\n",
      "-------------------------------------\n",
      "diff_count: 20000\n",
      "-------------------------------------\n",
      "-------------3th fold----------------\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github-desktop\\Unlabeled-Fairness\\src\\benchmark_methods\\benchmark_methods.py:443: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(mmd_score)  # Return the square root for interpretability\n",
      "d:\\Github-desktop\\Unlabeled-Fairness\\src\\benchmark_methods\\benchmark_methods.py:443: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(mmd_score)  # Return the square root for interpretability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_count: 20000\n",
      "-------------------------------------\n",
      "-------------4th fold----------------\n",
      "-------------------------------------\n",
      "diff_count: 20000\n",
      "✅ german_credit 处理后结果已保存到 saved_results/sota_results\\correlation_removal_results.csv\n",
      "-------------------------------------\n",
      "---!! on compas dataset !!---\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------0th fold----------------\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github-desktop\\Unlabeled-Fairness\\src\\benchmark_methods\\benchmark_methods.py:443: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(mmd_score)  # Return the square root for interpretability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_count: 93437\n",
      "-------------------------------------\n",
      "-------------1th fold----------------\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github-desktop\\Unlabeled-Fairness\\src\\benchmark_methods\\benchmark_methods.py:443: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(mmd_score)  # Return the square root for interpretability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_count: 93482\n",
      "-------------------------------------\n",
      "-------------2th fold----------------\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github-desktop\\Unlabeled-Fairness\\src\\benchmark_methods\\benchmark_methods.py:443: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(mmd_score)  # Return the square root for interpretability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_count: 93435\n",
      "-------------------------------------\n",
      "-------------3th fold----------------\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github-desktop\\Unlabeled-Fairness\\src\\benchmark_methods\\benchmark_methods.py:443: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(mmd_score)  # Return the square root for interpretability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_count: 98107\n",
      "-------------------------------------\n",
      "-------------4th fold----------------\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github-desktop\\Unlabeled-Fairness\\src\\benchmark_methods\\benchmark_methods.py:443: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(mmd_score)  # Return the square root for interpretability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_count: 98124\n",
      "✅ compas 处理后结果已保存到 saved_results/sota_results\\correlation_removal_results.csv\n",
      "-------------------------------------\n",
      "---!! on compas4race dataset !!---\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------0th fold----------------\n",
      "-------------------------------------\n",
      "diff_count: 61085\n",
      "-------------------------------------\n",
      "-------------1th fold----------------\n",
      "-------------------------------------\n",
      "diff_count: 61054\n",
      "-------------------------------------\n",
      "-------------2th fold----------------\n",
      "-------------------------------------\n",
      "diff_count: 58100\n",
      "-------------------------------------\n",
      "-------------3th fold----------------\n",
      "-------------------------------------\n",
      "diff_count: 61087\n",
      "-------------------------------------\n",
      "-------------4th fold----------------\n",
      "-------------------------------------\n",
      "diff_count: 58112\n",
      "✅ compas4race 处理后结果已保存到 saved_results/sota_results\\correlation_removal_results.csv\n",
      "-------------------------------------\n",
      "---!! on adult dataset !!---\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------0th fold----------------\n",
      "-------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmark_methods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmark_methods\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BenchMarkPreprocessingMethods\n\u001b[0;32m      3\u001b[0m sota \u001b[38;5;241m=\u001b[39m BenchMarkPreprocessingMethods(sota_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrelation_removal\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# 'disparate_impact', 'correlation_removal', 'reweighing',\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43msota\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_and_save_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_origin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# save_origin=True if you want to save the original dataset's results\u001b[39;00m\n",
      "File \u001b[1;32md:\\Github-desktop\\Unlabeled-Fairness\\src\\benchmark_methods\\benchmark_methods.py:150\u001b[0m, in \u001b[0;36mBenchMarkPreprocessingMethods.run_and_save_results\u001b[1;34m(self, save_origin)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msota_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrelation_removal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    149\u001b[0m     X_train_repair, X_val_repair\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_correlation_removal(X_train, X_val, repair_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m--> 150\u001b[0m     mmd_score \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_mmd_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_repair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m     wasserstein_scores \u001b[38;5;241m=\u001b[39m compute_wasserstein_fidelity(X_train\u001b[38;5;241m.\u001b[39mvalues, X_train_repair)\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# X_val_repair = self._correlation_removal(X_val, remove_ratio=1)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Github-desktop\\Unlabeled-Fairness\\src\\benchmark_methods\\benchmark_methods.py:434\u001b[0m, in \u001b[0;36mcompute_mmd_distance\u001b[1;34m(X1, X2, gamma)\u001b[0m\n\u001b[0;32m    432\u001b[0m K_xx \u001b[38;5;241m=\u001b[39m rbf_kernel(X1, X1, gamma\u001b[38;5;241m=\u001b[39mgamma)  \u001b[38;5;66;03m# Kernel within X1\u001b[39;00m\n\u001b[0;32m    433\u001b[0m K_yy \u001b[38;5;241m=\u001b[39m rbf_kernel(X2, X2, gamma\u001b[38;5;241m=\u001b[39mgamma)  \u001b[38;5;66;03m# Kernel within X2\u001b[39;00m\n\u001b[1;32m--> 434\u001b[0m K_xy \u001b[38;5;241m=\u001b[39m \u001b[43mrbf_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Kernel between X1 and X2\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;66;03m# Compute MMD^2 using the unbiased estimator (excluding diagonal elements)\u001b[39;00m\n\u001b[0;32m    437\u001b[0m mmd_xx \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39msum(K_xx) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mtrace(K_xx)) \u001b[38;5;241m/\u001b[39m (n1 \u001b[38;5;241m*\u001b[39m (n1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\ZhuLi\\anaconda3\\envs\\unlabel_fair\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ZhuLi\\anaconda3\\envs\\unlabel_fair\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1562\u001b[0m, in \u001b[0;36mrbf_kernel\u001b[1;34m(X, Y, gamma)\u001b[0m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gamma \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m     gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m-> 1562\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43meuclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1563\u001b[0m K \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mgamma\n\u001b[0;32m   1564\u001b[0m np\u001b[38;5;241m.\u001b[39mexp(K, K)  \u001b[38;5;66;03m# exponentiate K in-place\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ZhuLi\\anaconda3\\envs\\unlabel_fair\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ZhuLi\\anaconda3\\envs\\unlabel_fair\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:372\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    367\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    368\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    370\u001b[0m         )\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ZhuLi\\anaconda3\\envs\\unlabel_fair\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:407\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    404\u001b[0m     distances \u001b[38;5;241m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[0;32m    409\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.benchmark_methods.benchmark_methods import BenchMarkPreprocessingMethods\n",
    "\n",
    "sota = BenchMarkPreprocessingMethods(sota_method='correlation_removal') # 'disparate_impact', 'correlation_removal', 'reweighing',\n",
    "sota.run_and_save_results(save_origin=False)   # save_origin=True if you want to save the original dataset's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZhuLi\\Anaconda3\\envs\\unlabel_fair\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "---!! on german_credit dataset !!---\n",
      "-------------------------------------\n",
      "Age                   0\n",
      "Sex                   0\n",
      "Job                   0\n",
      "Housing               0\n",
      "Saving accounts     183\n",
      "Checking account    394\n",
      "Credit amount         0\n",
      "Duration              0\n",
      "Purpose               0\n",
      "Risk                  0\n",
      "dtype: int64\n",
      "-------------------------------------\n",
      "-------------0th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the german_credit dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (391, 26)\n",
      "X_train_majority_label1 shape: (152, 26)\n",
      "X_train_minority_label0 shape: (168, 26)\n",
      "X_train_minority_label1 shape: (89, 26)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 67\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 154\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改221个数据点, 使用new training set训练新模型\n",
      "top_positions: 221\n",
      "diff_count: 213\n",
      "-------------------------------------\n",
      "-------------1th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the german_credit dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (398, 26)\n",
      "X_train_majority_label1 shape: (153, 26)\n",
      "X_train_minority_label0 shape: (158, 26)\n",
      "X_train_minority_label1 shape: (91, 26)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 126\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 225\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改351个数据点, 使用new training set训练新模型\n",
      "top_positions: 351\n",
      "diff_count: 337\n",
      "-------------------------------------\n",
      "-------------2th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the german_credit dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (404, 26)\n",
      "X_train_majority_label1 shape: (153, 26)\n",
      "X_train_minority_label0 shape: (155, 26)\n",
      "X_train_minority_label1 shape: (88, 26)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 103\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 201\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改304个数据点, 使用new training set训练新模型\n",
      "top_positions: 304\n",
      "diff_count: 292\n",
      "-------------------------------------\n",
      "-------------3th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the german_credit dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (401, 26)\n",
      "X_train_majority_label1 shape: (156, 26)\n",
      "X_train_minority_label0 shape: (162, 26)\n",
      "X_train_minority_label1 shape: (81, 26)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 55\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 128\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改183个数据点, 使用new training set训练新模型\n",
      "top_positions: 183\n",
      "diff_count: 179\n",
      "-------------------------------------\n",
      "-------------4th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the german_credit dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (402, 26)\n",
      "X_train_majority_label1 shape: (150, 26)\n",
      "X_train_minority_label0 shape: (161, 26)\n",
      "X_train_minority_label1 shape: (87, 26)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 121\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 294\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改415个数据点, 使用new training set训练新模型\n",
      "top_positions: 415\n",
      "diff_count: 402\n",
      "✅ german_credit 处理后结果已保存到 saved_results/sota_results\\FairSHAP_OT_0.05_results.csv\n",
      "-------------------------------------\n",
      "---!! on compas dataset !!---\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------0th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the compas dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (2483, 18)\n",
      "X_train_majority_label1 shape: (2187, 18)\n",
      "X_train_minority_label0 shape: (703, 18)\n",
      "X_train_minority_label1 shape: (398, 18)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 230\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 1405\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改1635个数据点, 使用new training set训练新模型\n",
      "top_positions: 1635\n",
      "diff_count: 1583\n",
      "-------------------------------------\n",
      "-------------1th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the compas dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (2418, 18)\n",
      "X_train_majority_label1 shape: (2207, 18)\n",
      "X_train_minority_label0 shape: (734, 18)\n",
      "X_train_minority_label1 shape: (412, 18)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 238\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 1207\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改1445个数据点, 使用new training set训练新模型\n",
      "top_positions: 1445\n",
      "diff_count: 1403\n",
      "-------------------------------------\n",
      "-------------2th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the compas dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (2454, 18)\n",
      "X_train_majority_label1 shape: (2218, 18)\n",
      "X_train_minority_label0 shape: (711, 18)\n",
      "X_train_minority_label1 shape: (388, 18)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 162\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 913\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改1075个数据点, 使用new training set训练新模型\n",
      "top_positions: 1075\n",
      "diff_count: 1041\n",
      "-------------------------------------\n",
      "-------------3th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the compas dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (2449, 18)\n",
      "X_train_majority_label1 shape: (2214, 18)\n",
      "X_train_minority_label0 shape: (715, 18)\n",
      "X_train_minority_label1 shape: (393, 18)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 239\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 1383\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改1622个数据点, 使用new training set训练新模型\n",
      "top_positions: 1622\n",
      "diff_count: 1576\n",
      "-------------------------------------\n",
      "-------------4th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the compas dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (2460, 18)\n",
      "X_train_majority_label1 shape: (2186, 18)\n",
      "X_train_minority_label0 shape: (725, 18)\n",
      "X_train_minority_label1 shape: (401, 18)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 231\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 1274\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改1505个数据点, 使用new training set训练新模型\n",
      "top_positions: 1505\n",
      "diff_count: 1455\n",
      "✅ compas 处理后结果已保存到 saved_results/sota_results\\FairSHAP_OT_0.05_results.csv\n",
      "-------------------------------------\n",
      "---!! on compas4race dataset !!---\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------0th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the compas4race dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (1427, 13)\n",
      "X_train_majority_label1 shape: (1514, 13)\n",
      "X_train_minority_label0 shape: (1199, 13)\n",
      "X_train_minority_label1 shape: (780, 13)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 536\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 972\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改1508个数据点, 使用new training set训练新模型\n",
      "top_positions: 1508\n",
      "diff_count: 1441\n",
      "-------------------------------------\n",
      "-------------1th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the compas4race dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (1438, 13)\n",
      "X_train_majority_label1 shape: (1543, 13)\n",
      "X_train_minority_label0 shape: (1194, 13)\n",
      "X_train_minority_label1 shape: (745, 13)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 572\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 1138\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改1710个数据点, 使用new training set训练新模型\n",
      "top_positions: 1710\n",
      "diff_count: 1637\n",
      "-------------------------------------\n",
      "-------------2th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the compas4race dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (1432, 13)\n",
      "X_train_majority_label1 shape: (1529, 13)\n",
      "X_train_minority_label0 shape: (1181, 13)\n",
      "X_train_minority_label1 shape: (778, 13)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 613\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 1097\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改1710个数据点, 使用new training set训练新模型\n",
      "top_positions: 1710\n",
      "diff_count: 1632\n",
      "-------------------------------------\n",
      "-------------3th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the compas4race dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (1436, 13)\n",
      "X_train_majority_label1 shape: (1508, 13)\n",
      "X_train_minority_label0 shape: (1192, 13)\n",
      "X_train_minority_label1 shape: (784, 13)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 564\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 995\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改1559个数据点, 使用new training set训练新模型\n",
      "top_positions: 1559\n",
      "diff_count: 1507\n",
      "-------------------------------------\n",
      "-------------4th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the compas4race dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (1447, 13)\n",
      "X_train_majority_label1 shape: (1510, 13)\n",
      "X_train_minority_label0 shape: (1186, 13)\n",
      "X_train_minority_label1 shape: (777, 13)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n",
      "4(a). 使用FairSHAP, 从 X_train_majority_label0中找到合适的值替换X_train_minority_label0中的数据\n",
      "4(b). 使用FairSHAP, 从 X_train_majority_label1中找到合适的值替换X_train_minority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_minority中shapely value中大于0.05的值的个数有: 581\n",
      "--------接下来对majority group进行修改--------\n",
      "3(a). 将X_train_majority_label0与X_train_minority_label0进行匹配\n",
      "3(b). 将X_train_majority_label1与X_train_minority_label1进行匹配\n",
      "4(a). 使用fairshap, 从 X_train_minority_label0中找到合适的值替换X_train_majority_label0中的数据\n",
      "4(b). 使用fairshap, 从 X_train_minority_label1中找到合适的值替换X_train_majority_label1中的数据\n",
      "5. 计算出varphi和q\n",
      "在X_train_majority中shapely value中大于0.05的值的个数有: 1076\n",
      "7. 开始整理minority部分的修改和majority部分的修改并且合并新数据,共修改1657个数据点, 使用new training set训练新模型\n",
      "top_positions: 1657\n",
      "diff_count: 1576\n",
      "✅ compas4race 处理后结果已保存到 saved_results/sota_results\\FairSHAP_OT_0.05_results.csv\n",
      "-------------------------------------\n",
      "---!! on adult dataset !!---\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------0th fold----------------\n",
      "-------------------------------------\n",
      "1. Split the adult dataset into majority group and minority group according to the number of sensitive attribute, besides split by label 0 and label 1\n",
      "X_train_majority_label0 shape: (12045, 106)\n",
      "X_train_majority_label1 shape: (5391, 106)\n",
      "X_train_minority_label0 shape: (7649, 106)\n",
      "X_train_minority_label1 shape: (963, 106)\n",
      "2. 初始化FairnessExplainer\n",
      "--------接下来先对minority group进行修改--------\n",
      "3(a). 将X_train_minority_label0与X_train_majority_label0进行匹配\n",
      "3(b). 将X_train_minority_label1与X_train_majority_label1进行匹配\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfairshap_all_values\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FairSHAP\n\u001b[0;32m      3\u001b[0m fairshap \u001b[38;5;241m=\u001b[39m FairSHAP(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, matching_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOT\u001b[39m\u001b[38;5;124m'\u001b[39m, fairshap_base\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mfairshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_and_save_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Github-desktop\\Unlabeled-Fairness\\src\\experiments\\fairshap_all_values.py:120\u001b[0m, in \u001b[0;36mFairSHAP.run_and_save_results\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m     matching_minority_label1 \u001b[38;5;241m=\u001b[39m NearestNeighborDataMatcher(X_labeled\u001b[38;5;241m=\u001b[39mX_train_minority_label1, X_unlabeled\u001b[38;5;241m=\u001b[39mX_train_majority_label1)\u001b[38;5;241m.\u001b[39mmatch(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatching_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOT\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 120\u001b[0m     matching_minority_label0 \u001b[38;5;241m=\u001b[39m \u001b[43mOptimalTransportPolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_labeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_minority_label0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_majority_label0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     matching_minority_label1 \u001b[38;5;241m=\u001b[39m OptimalTransportPolicy(X_labeled\u001b[38;5;241m=\u001b[39mX_train_minority_label1\u001b[38;5;241m.\u001b[39mvalues, X_unlabeled\u001b[38;5;241m=\u001b[39mX_train_majority_label1\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mmatch()\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Github-desktop\\Unlabeled-Fairness\\src\\matching\\ot_matcher.py:30\u001b[0m, in \u001b[0;36mOptimalTransportPolicy.match\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 30\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobs_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mot_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumItermax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000000\u001b[39;49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobs_matrix \u001b[38;5;241m=\u001b[39m ot\u001b[38;5;241m.\u001b[39mbregman\u001b[38;5;241m.\u001b[39msinkhorn(\n\u001b[0;32m     35\u001b[0m             np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN,\n\u001b[0;32m     36\u001b[0m             np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m             numItermax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000000\u001b[39m,\n\u001b[0;32m     40\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ZhuLi\\Anaconda3\\envs\\unlabel_fair\\lib\\site-packages\\ot\\lp\\__init__.py:353\u001b[0m, in \u001b[0;36memd\u001b[1;34m(a, b, M, numItermax, log, center_dual, numThreads, check_marginals)\u001b[0m\n\u001b[0;32m    349\u001b[0m bsel \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    351\u001b[0m numThreads \u001b[38;5;241m=\u001b[39m check_number_threads(numThreads)\n\u001b[1;32m--> 353\u001b[0m G, cost, u, v, result_code \u001b[38;5;241m=\u001b[39m \u001b[43memd_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumItermax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumThreads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m center_dual:\n\u001b[0;32m    356\u001b[0m     u, v \u001b[38;5;241m=\u001b[39m center_ot_dual(u, v, a, b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.experiments.fairshap_all_values import FairSHAP\n",
    "\n",
    "fairshap = FairSHAP(threshold=0.05, matching_method='NN', fairshap_base='DR')\n",
    "fairshap.run_and_save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlabel_fair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
